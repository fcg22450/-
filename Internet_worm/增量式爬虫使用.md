[TOC]

# 1---增量式爬虫简介

### 概念: 

​	检测网站数据更新情况

### 核心:

​	去重

### 要点::

​	深度爬取类型的网站中需要对详情页的url进行记录和检测

#### 	记录:

​		将爬取过的详情页的url进行记录保存

​		将url存储到redis中去

#### 	检测:

​		在对某一个详情页的url发请求之前先要到记录表中进行查看,该url是否存在,如果存在的话,意味着这个url已经被爬取过了

# 2---使用流程及案例

### 深度爬取类型的网站使用增量式爬虫爬取数据:

```python
import scrapy
from scrapy.linkextractors import LinkExtractor
from scrapy.spiders import CrawlSpider, Rule
from redis import Redis
from ..items import ZlsMovieproItem


class ZlsSpider(CrawlSpider):
    name = 'zls'
    conn = Redis()
    # 设置初试url
    start_urls = ['https://www.4567tv.tv/index.php/vod/show/id/8.html']
    rules = (
        Rule(LinkExtractor(allow=r'id/8/page/\d+\.html'),
             callback='parse_item',
             follow=True),
    )

    def parse_item(self, response):
        # 进行数据解析,准备就进行深度爬取,
        # 因为这里的深度解析涉及两层页面,所以需要进行手动发送请求来确保更加精确
        li_list = response.xpath('//div[1]/div/div/div/div[2]/ul/li')
        for li in li_list:
            movie_name = li.xpath('./div/div/h4/a/text()').extract_first()
            detail_url = 'https://www.4567tv.tv' + li.xpath(
                './div/div/h4/a/@href').extract_first()
            # 进行数据插入,通过sadd的返回值来辨别数据是否重复
            # 将获取到的详情页的url存储到redis中
            # 在执行sadd操作的时候,如果要插入的数据已经存在,将会返回0,并且插入失败,如果不存在,返回1,插入成功
            ex = self.conn.sadd('movie_url_data', detail_url)
            if ex == 1:
                print('哦~一块新鲜的奶酪!')
                item = ZlsMovieproItem()
                item['movie_name'] = movie_name
                将获取到的电影名称存储到item并进行传递
                yield scrapy.Request(url=detail_url,
                                     callback=self.detail_parse,
                                     meta={'item': item})
            else:
                print('腐朽的味道!!!')

    def detail_parse(self, response):
        item = response.meta['item']
        detail_text = response.xpath(
            '//div[1]/div/div/div/div[2]/p[5]/span[3]/text()').extract_first()
        item['detail_text'] = detail_text
        print(item)
        yield item
```

### 不需要深度爬取的网站的注意点:

数据指纹:

​	一组数据的唯一标识

​	在数据库中构建指纹集合,换句话说,就是创建一个绝对不会重复的id,来确保数据爬取的时候不会重复获取已有的数据

# 3---核心要点

